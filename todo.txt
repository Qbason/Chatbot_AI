TODOS:
    - create docker-compose.yaml for local deployment
    - implement backend:
        - create mockup for OPENAI service -> lorem ipsum etc.
        - optimize saving chunks - too much IO database
        - use GUID
    - implement frontend
        - improve warning while logging in (bad credentials)
        - add markdown to message
        - setup prettier and lint
    - write readme how to run


Thoughts:
    Idea of api:
        /api/conversations for getting all conversations
        /api/conversations/{id} for getting details about
        /api/conversations POST it creates conversation and stream via EventStream
        /api/conversations/message_feedback -> conversation_id, message_id, rating: "thumbsUp/thumbsDown"

        /api/chat/stream -stream content of AI message -> event delta for chunks
        /api/chat/stop_conversation -> stop streaming (cancelation token) by conversation id
